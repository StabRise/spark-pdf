{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "213c2c2d-1d67-4b1f-bd46-23ba3f761210",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "<p align=\"center\">\n",
    "  <br/>\n",
    "    <a href=\"https://stabrise.com/spark-pdf/\"><img alt=\"Spark Pdf\" src=\"https://stabrise.com/static/images/projects/sparkpdf.webp\" style=\"max-width: 100%;\"></a>\n",
    "  <br/>\n",
    "</p>\n",
    "\n",
    "This notebook demonstrates how to use the PDF Datasource to read PDF files from Unity Catalog volume on Databricks.\n",
    "\n",
    "<p align=\"center\">\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/StabRise/spark-pdf/blob/main/examples/PdfDataSource.ipynb\">\n",
    "      <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "    </a>\n",
    "    <a href=\"https://search.maven.org/artifact/com.stabrise/spark-pdf-spark35_2.12\">\n",
    "        <img alt=\"Maven Central Version\" src=\"https://img.shields.io/maven-central/v/com.stabrise/spark-pdf-spark35_2.12\">\n",
    "    </a>\n",
    "    <a href=\"https://github.com/StabRise/spark-pdf/blob/master/LICENSE\" >\n",
    "        <img src=\"https://img.shields.io/badge/License-AGPL%203-blue.svg\" alt=\"License\"/>\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "---\n",
    "\n",
    "**Source Code**: [https://github.com/StabRise/spark-pdf](https://github.com/StabRise/spark-pdf)\n",
    "\n",
    "**Related Blog Posts**: \n",
    " - [https://stabrise.com/blog/spark-pdf-databricks-unity-catalog/](https://stabrise.com/blog/spark-pdf-databricks-unity-catalog/)\n",
    " - [https://stabrise.com/blog/spark-pdf-on-databricks/](https://stabrise.com/blog/spark-pdf-on-databricks/)\n",
    "\n",
    "⭐ Star us on GitHub — it motivates us a lot!\n",
    "\n",
    "---\n",
    "\n",
    "## Key features:\n",
    "\n",
    "- Read PDF documents to the Spark DataFrame\n",
    "- Support read PDF files lazy per page\n",
    "- Support big files, up to 10k pages\n",
    "- Support scanned PDF files (call OCR)\n",
    "- No need to install Tesseract OCR, it's included in the package\n",
    "\n",
    "## Requirements\n",
    "\n",
    "- Databricks runtime v15.04 or above (Spark v3.5.x)\n",
    "- Spark PDF v0.1.16 or above (maven: com.stabrise:spark-pdf-spark35_2.12:0.1.16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:43:02.160090485Z",
     "start_time": "2024-12-06T06:42:57.235384559Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ffef174-4469-432e-8e1f-96eec5ede46f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ffb72fe7-3999-40a2-9fed-ca6f8059b567",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-24T17:00:14.537434Z",
     "iopub.status.busy": "2024-11-24T17:00:14.537180Z",
     "iopub.status.idle": "2024-11-24T17:00:14.540956Z",
     "shell.execute_reply": "2024-11-24T17:00:14.540241Z",
     "shell.execute_reply.started": "2024-11-24T17:00:14.537416Z"
    }
   },
   "source": "## Download example files and copy it to the Unty Catalog volume"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:43:13.284434400Z",
     "start_time": "2024-12-06T06:43:10.951484687Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4bfae71-2d69-4de3-b1a6-530b9cbf5b0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-25T05:34:34.317886Z",
     "iopub.status.busy": "2024-11-25T05:34:34.317599Z",
     "iopub.status.idle": "2024-11-25T05:34:34.322615Z",
     "shell.execute_reply": "2024-11-25T05:34:34.321685Z",
     "shell.execute_reply.started": "2024-11-25T05:34:34.317864Z"
    }
   },
   "outputs": [],
   "source": [
    "CATALOG_NAME = \"your catalog\"\n",
    "SCHEMA_NAME = \"default\"\n",
    "VOLUME_NAME = \"your volume\"\n",
    "\n",
    "\n",
    "# Downloading example PDF files\n",
    "\n",
    "filenames = [\"example1.pdf\", \"example2.pdf\", \"example3.pdf\"]\n",
    "url = f\"https://raw.githubusercontent.com/StabRise/spark-pdf/refs/heads/main/examples/\"\n",
    "for filename in filenames:\n",
    "    urllib.request.urlretrieve(url + filename, filename)\n",
    "    volume_path = f\"/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}/{VOLUME_NAME}/{filename}\"\n",
    "    dbutils.fs.cp (f\"file:{os.getcwd()}/{filename}\", volume_path)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading pdf documents to the Spark"
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:43:15.890138797Z",
     "start_time": "2024-12-06T06:43:14.986337055Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70a305da-9b62-4a75-926c-8a6e612c4d76",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2024-11-25T05:34:43.702960Z",
     "iopub.status.busy": "2024-11-25T05:34:43.702669Z",
     "iopub.status.idle": "2024-11-25T05:34:44.454923Z",
     "shell.execute_reply": "2024-11-25T05:34:44.454263Z",
     "shell.execute_reply.started": "2024-11-25T05:34:43.702940Z"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"pdf\") \\\n",
    "    .option(\"imageType\", \"BINARY\") \\\n",
    "    .option(\"resolution\", \"300\") \\\n",
    "    .option(\"pagePerPartition\", \"8\") \\\n",
    "    .option(\"reader\", \"pdfBox\") \\\n",
    "    .load(f\"/Volumes/{CATALOG_NAME}/{SCHEMA_NAME}/{VOLUME_NAME}/*.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "265cafad-c53c-454c-817d-3022e930ef67",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Available options for the data source:\n",
    "\n",
    "- `imageType`: Oputput image type. Can be: \"BINARY\", \"GREY\", \"RGB\". Default: \"RGB\".\n",
    "- `resolution`: Resolution for rendering PDF page to the image. Default: \"300\" dpi.\n",
    "- `pagePerPartition`: Number pages per partition in Spark DataFrame. Default: \"5\".\n",
    "- `reader`: Supports: `pdfBox` - based on PdfBox java lib, `gs` - based on GhostScript (need installation GhostScipt to the system)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3778dcc4-638f-4146-9431-872c8de9c1ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Counting total number of pages in all documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1088b05-8232-4f9a-92d7-6e225714ddce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Spark PDF operates with a lazy evaluation approach, extracting metadata from PDF files without loading the entire file into memory.\n",
    "\n",
    "In this example, we loaded two PDF documents:  \n",
    "- The first document contains 1 page.  \n",
    "- The second document contains 1 page with not recognized text.\n",
    "- The last one document contains 30 pages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:43:20.891688410Z",
     "start_time": "2024-12-06T06:43:19.837926036Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba5ca0b1-62f6-46fe-9f8c-5249156e8b89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-25T05:34:48.341186Z",
     "iopub.status.busy": "2024-11-25T05:34:48.340833Z",
     "iopub.status.idle": "2024-11-25T05:34:49.132473Z",
     "shell.execute_reply": "2024-11-25T05:34:49.132176Z",
     "shell.execute_reply.started": "2024-11-25T05:34:48.341159Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 4,
     "metadata": {}
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f762e62d-8553-4df7-8bb0-46540f23233d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Checking Number of Partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2fd64945-7562-47ec-820b-2883f063d20b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "We specified the option `pagePerPartition = 8` in the configuration.<br/>\n",
    "This results in 6 partitions:  \n",
    "- 1 partition for the first file.  \n",
    "- 1 partition for the second file.  \n",
    "- 4 partitions for the last file, which contains 30 pages.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:43:29.053990731Z",
     "start_time": "2024-12-06T06:43:28.957038747Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba35844d-f626-48e8-86f6-b7a79a74bd18",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-25T05:34:52.207297Z",
     "iopub.status.busy": "2024-11-25T05:34:52.206923Z",
     "iopub.status.idle": "2024-11-25T05:34:52.309338Z",
     "shell.execute_reply": "2024-11-25T05:34:52.308942Z",
     "shell.execute_reply.started": "2024-11-25T05:34:52.207266Z"
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 5,
     "metadata": {}
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfac2a36-ce6f-4bd0-b520-3b093645e357",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Showing the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bffb84a3-95bc-4862-9ec4-616e00f5d77b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The DataFrame contains the following columns:\n",
    "\n",
    "- `path`: path to the file\n",
    "- `page_number`: page number of the document\n",
    "- `text`: extracted text from the text layer of the PDF page\n",
    "- `image`: image representation of the page\n",
    "- `document`: the OCR-extracted text from the rendered image (calls Tesseract OCR)\n",
    "- `partition_number`: partition number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T06:43:32.072166793Z",
     "start_time": "2024-12-06T06:43:31.608321507Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9028ccec-be17-4775-a6ba-26ce8e98ee77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-25T05:36:08.409314Z",
     "iopub.status.busy": "2024-11-25T05:36:08.409029Z",
     "iopub.status.idle": "2024-11-25T05:36:08.593900Z",
     "shell.execute_reply": "2024-11-25T05:36:08.593303Z",
     "shell.execute_reply.started": "2024-11-25T05:36:08.409293Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+------------+-----------+----------------+--------------------+\n|    filename|page_number|partition_number|                text|\n+------------+-----------+----------------+--------------------+\n|example1.pdf|          0|               4|RECIPE\\nStrawberr...|\n|example2.pdf|          0|               5|                  \\n|\n|example3.pdf|          0|               0|Lorem ipsum \\nLor...|\n|example3.pdf|          1|               0|In non mauris jus...|\n|example3.pdf|          2|               0|Lorem ipsum dolor...|\n|example3.pdf|          3|               0|Maecenas mauris l...|\n|example3.pdf|          4|               0|Etiam vehicula lu...|\n|example3.pdf|          5|               0|Lorem ipsum \\nLor...|\n|example3.pdf|          6|               0|In non mauris jus...|\n|example3.pdf|          7|               0|Lorem ipsum dolor...|\n|example3.pdf|          8|               1|Maecenas mauris l...|\n|example3.pdf|          9|               1|Etiam vehicula lu...|\n|example3.pdf|         10|               1|Lorem ipsum \\nLor...|\n|example3.pdf|         11|               1|In non mauris jus...|\n|example3.pdf|         12|               1|Lorem ipsum dolor...|\n|example3.pdf|         13|               1|Maecenas mauris l...|\n|example3.pdf|         14|               1|Etiam vehicula lu...|\n|example3.pdf|         15|               1|Lorem ipsum \\nLor...|\n|example3.pdf|         16|               2|In non mauris jus...|\n|example3.pdf|         17|               2|Lorem ipsum dolor...|\n+------------+-----------+----------------+--------------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"filename\", \"page_number\", \"partition_number\", \"text\") \\\n",
    "    .orderBy(\"filename\", \"page_number\") \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-25T10:29:25.972668366Z",
     "start_time": "2024-11-25T10:29:25.924994443Z"
    },
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abb74fc7-071d-4600-802b-1c0d251ec084",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "execution": {
     "iopub.execute_input": "2024-11-25T05:36:30.175478Z",
     "iopub.status.busy": "2024-11-25T05:36:30.175158Z",
     "iopub.status.idle": "2024-11-25T05:36:30.182175Z",
     "shell.execute_reply": "2024-11-25T05:36:30.181475Z",
     "shell.execute_reply.started": "2024-11-25T05:36:30.175456Z"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "root\n |-- path: string (nullable = true)\n |-- filename: string (nullable = true)\n |-- page_number: integer (nullable = true)\n |-- partition_number: integer (nullable = true)\n |-- text: string (nullable = true)\n |-- image: struct (nullable = true)\n |    |-- path: string (nullable = true)\n |    |-- resolution: integer (nullable = true)\n |    |-- data: binary (nullable = true)\n |    |-- imageType: string (nullable = true)\n |    |-- exception: string (nullable = true)\n |    |-- height: integer (nullable = true)\n |    |-- width: integer (nullable = true)\n |-- document: struct (nullable = true)\n |    |-- path: string (nullable = true)\n |    |-- text: string (nullable = true)\n |    |-- outputType: string (nullable = true)\n |    |-- bBoxes: array (nullable = true)\n |    |    |-- element: struct (containsNull = true)\n |    |    |    |-- text: string (nullable = true)\n |    |    |    |-- score: float (nullable = true)\n |    |    |    |-- x: integer (nullable = true)\n |    |    |    |-- y: integer (nullable = true)\n |    |    |    |-- width: integer (nullable = true)\n |    |    |    |-- height: integer (nullable = true)\n |    |-- exception: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6444390799100077,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "PdfDataSource",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
